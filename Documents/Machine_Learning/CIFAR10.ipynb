{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5PTLP1xzkbRm"
      },
      "outputs": [],
      "source": [
        "import os, sys, time, random\n",
        "import torch, torchvision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD54SVv3khD_",
        "outputId": "46dcc9ea-1539-4c64-9994-3e26cbc6f551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Compute capability: 7.5\n",
            "VRAM GB: 14.74\n",
            "RUN_DIR: /content/outputs/run_20251025-040551\n",
            "CKPT_DIR: /content/outputs/run_20251025-040551/checkpoints\n",
            "LOG_DIR: /content/outputs/run_20251025-040551/logs\n"
          ]
        }
      ],
      "source": [
        "# check if a CUDA-capable GPU is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# choose the compute device based on CUDA availability\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# print whether CUDA is available\n",
        "print(\"CUDA available:\", use_cuda)\n",
        "\n",
        "# if CUDA is available, print GPU details\n",
        "if use_cuda:\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(\"Compute capability:\", f\"{props.major}.{props.minor}\")\n",
        "    # print total GPU memory in gigabytes rounded to two decimals\n",
        "    print(\"VRAM GB:\", round(props.total_memory/1024**3, 2))\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "# seed PyTorch’s CPU random number generator\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# disable cuDNN autotuner to avoid nondeterministic algorithms\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "RUN_ID = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "BASE_DIR = os.getcwd()\n",
        "#top-level outputs directory path\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
        "#subfolder\n",
        "RUN_DIR = os.path.join(OUTPUT_DIR, f\"run_{RUN_ID}\")\n",
        "#subfolder to store model checkpoints\n",
        "CKPT_DIR = os.path.join(RUN_DIR, \"checkpoints\")\n",
        "# subfolder to store logs and metrics\n",
        "LOG_DIR = os.path.join(RUN_DIR, \"logs\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "info_path = os.path.join(RUN_DIR, \"RUN_INFO.txt\")\n",
        "\n",
        "# open the run info file for writing\n",
        "with open(info_path, \"w\") as f:\n",
        "    f.write(f\"RUN_ID={RUN_ID}\\n\")\n",
        "    f.write(f\"Python={sys.version}\\n\")\n",
        "    f.write(f\"PyTorch={torch.__version__}\\n\")\n",
        "    f.write(f\"TorchVision={torchvision.__version__}\\n\")\n",
        "    f.write(f\"CUDA={use_cuda}\\n\")\n",
        "    if use_cuda:\n",
        "        f.write(f\"GPU={torch.cuda.get_device_name(0)}\\n\")\n",
        "        f.write(f\"ComputeCap={props.major}.{props.minor}\\n\")\n",
        "        f.write(f\"VRAM_GB={props.total_memory/1024**3:.2f}\\n\")\n",
        "\n",
        "    f.write(f\"SEED={SEED}\\n\")\n",
        "    f.write(f\"DEVICE={device}\\n\")\n",
        "\n",
        "print(\"RUN_DIR:\", RUN_DIR)\n",
        "print(\"CKPT_DIR:\", CKPT_DIR)\n",
        "print(\"LOG_DIR:\", LOG_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLNOtmuV_iED",
        "outputId": "9350387d-e583-40df-f61b-f8558d0aac2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: 50000 Test images: 10000\n",
            "Test batch: torch.Size([128, 3, 32, 32]) torch.float32 | labels: torch.Size([128]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "\n",
        "# batch size increased from 4 to 128 to make it faster\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# enable pinned memory for faster host→GPU copies when on CUDA\n",
        "PIN_MEMORY = True if getattr(device, \"type\", \"cpu\") == \"cuda\" else False\n",
        "\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                     (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                     (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# create CIFAR-10 training dataset object (50k images)\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=DATA_DIR, train=True, download=True, transform=train_transform\n",
        ")\n",
        "\n",
        "# create CIFAR-10 test dataset object (10k images)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=DATA_DIR, train=False, download=True, transform=test_transform\n",
        ")\n",
        "\n",
        "# build a DataLoader for the test set #batchwise\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
        ")\n",
        "\n",
        "# print dataset sizes to verify download and object creation\n",
        "print(\"Train images:\", len(train_dataset), \"Test images:\", len(test_dataset))\n",
        "\n",
        "# pull one batch from the test loader for a quick shape/type check\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# show tensor shapes and dtypes to confirm expectations\n",
        "print(\"Test batch:\", images.shape, images.dtype, \"| labels:\", labels.shape, labels.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3_InMi1tXZC",
        "outputId": "ab9f2ffa-9921-46fc-ab0e-69f812d9c498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold sizes — X: 16667 Y: 16667 Z: 16666\n",
            "[Fold with val=X] train samples: 33333 | val samples: 16667\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "# get total number of training examples\n",
        "n_total = len(train_dataset)\n",
        "\n",
        "# for reproducible shuffling\n",
        "rng = np.random.RandomState(SEED)\n",
        "\n",
        "# build a list of all training indices [0, 1, ..., n_total-1]\n",
        "all_indices = np.arange(n_total)\n",
        "\n",
        "# shuffle the indices deterministically using the seeded RNG\n",
        "rng.shuffle(all_indices)\n",
        "\n",
        "# split the shuffled indices into three nearly-equal folds: X, Y, Z\n",
        "X_idx, Y_idx, Z_idx = np.array_split(all_indices, 3)\n",
        "\n",
        "# convert folds to Python lists\n",
        "X_idx = X_idx.tolist()\n",
        "Y_idx = Y_idx.tolist()\n",
        "Z_idx = Z_idx.tolist()\n",
        "\n",
        "# store folds in a dict for easy lookup by name\n",
        "FOLDS = {\"X\": X_idx, \"Y\": Y_idx, \"Z\": Z_idx}\n",
        "\n",
        "print(\"Fold sizes — X:\", len(FOLDS[\"X\"]), \"Y:\", len(FOLDS[\"Y\"]), \"Z:\", len(FOLDS[\"Z\"]))\n",
        "\n",
        "# dedicated torch.Generator seeded for deterministic sampling order\n",
        "loader_generator = torch.Generator()\n",
        "loader_generator.manual_seed(SEED)\n",
        "\n",
        "#helper that builds a DataLoader over a given subset of indices\n",
        "def _make_loader(dataset, indices, batch_size, num_workers, pin_memory):\n",
        "    sampler = SubsetRandomSampler(indices, generator=loader_generator)\n",
        "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler,\n",
        "                      num_workers=num_workers, pin_memory=pin_memory, drop_last=False)\n",
        "\n",
        "#function that returns (train_loader, val_loader) for a chosen validation fold\n",
        "def get_fold_loaders(val_fold: str, batch_size=BATCH_SIZE):\n",
        "    assert val_fold in FOLDS, f\"val_fold must be one of {list(FOLDS.keys())}\"\n",
        "    val_idx = FOLDS[val_fold]\n",
        "\n",
        "    train_idx = []\n",
        "    # iterate over all fold names and add those that are not the validation fold\n",
        "    for name, idxs in FOLDS.items():\n",
        "        if name != val_fold:\n",
        "            train_idx.extend(idxs)\n",
        "    # build the training DataLoader using the combined indices\n",
        "    train_loader = _make_loader(train_dataset, train_idx, batch_size, NUM_WORKERS, PIN_MEMORY)\n",
        "    val_loader = _make_loader(train_dataset, val_idx, batch_size, NUM_WORKERS, PIN_MEMORY)\n",
        "\n",
        "    # short summary of subset sizes for this fold\n",
        "    print(f\"[Fold with val={val_fold}] train samples: {len(train_idx)} | val samples: {len(val_idx)}\")\n",
        "    # return both loaders to the caller\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# optionally instantiate loaders for Fold-1 (val = X) to verify everything works\n",
        "train_loader_F1, val_loader_F1 = get_fold_loaders(\"X\", batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BML_VIZRhDX-",
        "outputId": "e8281d72-c370-4b12-c13a-5e0bcc320076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arch-A params: 1070986\n",
            "Arch-B params: 2777674\n",
            "Arch-A output: torch.Size([2, 10])\n",
            "Arch-B output: torch.Size([2, 10])\n"
          ]
        }
      ],
      "source": [
        "#two architectures: Arch-A (Plain CNN) and Arch-B (ResNet-style)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "#Arch-A: plain CNN for CIFAR-10 classification\n",
        "class BasicCNN(nn.Module):\n",
        "    # initialize layers for the plain CNN\n",
        "    def __init__(self, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        # first conv block: 3->32 channels, 3x3 kernel with padding=1 keeps H,W the same\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        # batch normalization after first conv\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        # nonlinearity\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        # downsampling 2x via max pooling\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # second conv block: 32->64 channels, again 3x3 with padding=1\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        # batch normalization after second conv\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # nonlinearity\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        # downsampling 2x via max pooling\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # dropout to regularize the fully-connected part\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "        # fully-connected hidden layer: 64 * 8 * 8 features -> 256 units\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
        "        # nonlinearity\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        # final classification layer to 10 classes\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # apply first conv block: conv -> bn -> relu -> pool\n",
        "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        # apply second conv block: conv -> bn -> relu -> pool\n",
        "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "        # flatten feature map to (batch, features)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # fully-connected hidden with dropout and relu\n",
        "        x = self.relu3(self.fc1(self.drop(x)))\n",
        "        # final logits\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    #Arch-B: ResNet-style with residual blocks (lightweight for CIFAR-10)\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    # initialize residual block with in/out channels and stride\n",
        "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        # first 3x3 conv (may stride for downsampling)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # batch norm after first conv\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        # relu nonlinearity\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # second 3x3 conv keeps spatial size (stride=1)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        # batch norm after second conv\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        #downsample to match identity shape when channels/stride change\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        # save identity for the skip connection\n",
        "        identity = x\n",
        "        # conv1 -> bn1 -> relu path\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        # conv2 -> bn2 path\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        # apply downsample to identity if provided\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        # add skip connection\n",
        "        out += identity\n",
        "        # final relu\n",
        "        out = self.relu(out)\n",
        "        # return block output\n",
        "        return out\n",
        "\n",
        "class ResNetLite(nn.Module):\n",
        "    # initialize the ResNet-like network\n",
        "    def __init__(self, block=BasicBlock, layers=(2, 2, 2), num_classes: int = 10, base_width: int = 64):\n",
        "        super().__init__()\n",
        "        # initial conv keeps 32x32 size (3x3, stride=1, pad=1)\n",
        "        self.in_planes = base_width\n",
        "        # first conv maps RGB to base_width channels\n",
        "        self.conv1 = nn.Conv2d(3, base_width, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        # batch norm after first conv\n",
        "        self.bn1 = nn.BatchNorm2d(base_width)\n",
        "        # nonlinearity\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # layer1: keep spatial size, channels = base_width\n",
        "        self.layer1 = self._make_layer(block, planes=base_width, blocks=layers[0], stride=1)\n",
        "        # layer2: downsample 32->16, channels = 2*base_width\n",
        "        self.layer2 = self._make_layer(block, planes=base_width * 2, blocks=layers[1], stride=2)\n",
        "        # layer3: downsample 16->8, channels = 4*base_width\n",
        "        self.layer3 = self._make_layer(block, planes=base_width * 4, blocks=layers[2], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # final linear layer from channels to classes\n",
        "        self.fc = nn.Linear(base_width * 4 * block.expansion, num_classes)\n",
        "\n",
        "    # helper to build a stack of residual blocks\n",
        "    def _make_layer(self, block, planes, blocks, stride):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_planes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "        layers = [block(self.in_planes, planes, stride=stride, downsample=downsample)]\n",
        "        # update current number of input planes after first block\n",
        "        self.in_planes = planes * block.expansion\n",
        "        # add remaining blocks (stride=1)\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_planes, planes, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # initial conv -> bn -> relu\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        # pass through three residual layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        # global average pool to (batch, channels, 1, 1)\n",
        "        x = self.avgpool(x)\n",
        "        # flatten to (batch, channels)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # linear classifier to logits\n",
        "        x = self.fc(x)\n",
        "        # return logits tensor of shape [batch, num_classes]\n",
        "        return x\n",
        "\n",
        "#  helper to count parameters in a model\n",
        "def count_parameters(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "model_A = BasicCNN(num_classes=10).to(device)\n",
        "model_B = ResNetLite(num_classes=10, base_width=64, layers=(2, 2, 2)).to(device)\n",
        "\n",
        "# print number of parameters for both models\n",
        "print(\"Arch-A params:\", count_parameters(model_A))\n",
        "print(\"Arch-B params:\", count_parameters(model_B))\n",
        "\n",
        "# forward pass with a fake batch to verify output shapes\n",
        "with torch.no_grad():\n",
        "    dummy = torch.randn(2, 3, 32, 32, device=device)\n",
        "    # forward through Arch-A\n",
        "    out_A = model_A(dummy)\n",
        "    # forward through Arch-B\n",
        "    out_B = model_B(dummy)\n",
        "    print(\"Arch-A output:\", out_A.shape)\n",
        "    print(\"Arch-B output:\", out_B.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SleKrdyW9b6R"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#cross-entropy loss for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# helper to build an SGD optimizer (you can switch to Adam later if needed)\n",
        "def make_optimizer(model, lr=0.01, momentum=0.9, weight_decay=5e-4):\n",
        "    return torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "# single training epoch (one full pass over train loader)\n",
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss, running_correct, running_total = 0.0, 0, 0\n",
        "    start_time = time.time()\n",
        "    # iterate over mini-batches from the training loader\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # forward pass to obtain logits\n",
        "        logits = model(images)\n",
        "        # compute cross-entropy loss between logits and labels\n",
        "        loss = criterion(logits, labels)\n",
        "        # backpropagate to compute gradients\n",
        "        loss.backward()\n",
        "        # update model parameters using the optimizer\n",
        "        optimizer.step()\n",
        "        # accumulate running loss scaled by batch size\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "        # compute batch accuracy and add to running correct count\n",
        "        running_correct += (logits.argmax(1) == labels).sum().item()\n",
        "        # add batch size to running total\n",
        "        running_total += labels.size(0)\n",
        "    # compute average loss over all samples in the epoch\n",
        "    avg_loss = running_loss / max(1, running_total)\n",
        "    # compute accuracy over the whole epoch\n",
        "    avg_acc = running_correct / max(1, running_total)\n",
        "    # measure elapsed time for the epoch\n",
        "    elapsed = time.time() - start_time\n",
        "    # return average loss, average accuracy, and epoch time (seconds)\n",
        "    return avg_loss, avg_acc, elapsed\n",
        "\n",
        "# evaluation loop (no gradients) for val/test\n",
        "def evaluate(model, loader, device):\n",
        "    # set model to evaluation mode (disables dropout, uses BN running stats)\n",
        "    model.eval()\n",
        "    # initialize running totals\n",
        "    running_loss, running_correct, running_total = 0.0, 0, 0\n",
        "    # no gradient tracking during evaluation\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            # move images and labels to device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            running_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            running_total += labels.size(0)\n",
        "    # compute average loss\n",
        "    avg_loss = running_loss / max(1, running_total)\n",
        "    # compute accuracy\n",
        "    avg_acc = running_correct / max(1, running_total)\n",
        "    # return average loss and accuracy\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "# helper to save a checkpoint to disk\n",
        "def save_checkpoint(path, model, optimizer, epoch, val_acc, meta: dict):\n",
        "    # build a dictionary that includes model/optimizer state and metadata\n",
        "    state = {\n",
        "        \"epoch\": epoch,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"meta\": meta,\n",
        "    }\n",
        "    # create parent directory if it does not exist\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    # save the checkpoint dictionary using torch.save\n",
        "    torch.save(state, path)\n",
        "\n",
        "# trains for multiple epochs on a chosen fold with checkpointing\n",
        "def train_for_fold(model, arch_name: str, val_fold: str, num_epochs: int = 10, lr: float = 0.01):\n",
        "    # get train and val loaders for the requested validation fold (X, Y, or Z)\n",
        "    train_loader, val_loader = get_fold_loaders(val_fold, batch_size=BATCH_SIZE)\n",
        "\n",
        "    optimizer = make_optimizer(model, lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    best_val_acc = -1.0\n",
        "    # build file paths for best and last checkpoints for this (arch, fold)\n",
        "    best_ckpt = os.path.join(CKPT_DIR, f\"{arch_name}_val{val_fold}_best-val.pth\")\n",
        "    last_ckpt = os.path.join(CKPT_DIR, f\"{arch_name}_val{val_fold}_last.pth\")\n",
        "    # iterate over epochs\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        tr_loss, tr_acc, tr_time = train_one_epoch(model, train_loader, optimizer, device)\n",
        "        va_loss, va_acc = evaluate(model, val_loader, device)\n",
        "        print(f\"[{arch_name} | val={val_fold}] epoch {epoch:03d} | \"\n",
        "              f\"train: loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "              f\"val: loss {va_loss:.4f} acc {va_acc:.4f} | \"\n",
        "              f\"time {tr_time:.1f}s\")\n",
        "        meta = {\"arch\": arch_name, \"val_fold\": val_fold, \"run_id\": RUN_ID}\n",
        "        save_checkpoint(last_ckpt, model, optimizer, epoch, va_acc, meta)\n",
        "        if va_acc > best_val_acc:\n",
        "            # update the best validation accuracy tracker\n",
        "            best_val_acc = va_acc\n",
        "            # save the best-val checkpoint to disk\n",
        "            save_checkpoint(best_ckpt, model, optimizer, epoch, va_acc, meta)\n",
        "    return best_val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vKbOiVPVBaMK"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "\n",
        "#CSV logger that writes a header once and appends rows\n",
        "class CSVLogger:\n",
        "    # initialize with a file path and the field names (header columns)\n",
        "    def __init__(self, path: str, fieldnames: list[str]):\n",
        "        self.path = path\n",
        "        self.fieldnames = fieldnames\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        if not os.path.exists(self.path):\n",
        "            with open(self.path, mode=\"w\", newline=\"\") as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n",
        "                # write the header row\n",
        "                writer.writeheader()\n",
        "\n",
        "    # append a single row (dict matching fieldnames) to the CSV\n",
        "    def log(self, row: dict):\n",
        "        with open(self.path, mode=\"a\", newline=\"\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n",
        "            writer.writerow(row)\n",
        "\n",
        "# function that trains one fold and logs per-epoch metrics to CSV\n",
        "def train_for_fold_logged(model, arch_name: str, val_fold: str, num_epochs: int = 10, lr: float = 0.01):\n",
        "    train_loader, val_loader = get_fold_loaders(val_fold, batch_size=BATCH_SIZE)\n",
        "    # create an SGD optimizer for this model\n",
        "    optimizer = make_optimizer(model, lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    # prepare checkpoint file paths for this architecture and fold\n",
        "    best_ckpt = os.path.join(CKPT_DIR, f\"{arch_name}_val{val_fold}_best-val.pth\")\n",
        "    # prepare the 'last' checkpoint file path\n",
        "    last_ckpt = os.path.join(CKPT_DIR, f\"{arch_name}_val{val_fold}_last.pth\")\n",
        "    # set up a CSV file to store metrics for this (arch, fold)\n",
        "    log_csv = os.path.join(LOG_DIR, f\"{arch_name}_val{val_fold}_metrics.csv\")\n",
        "    # create a CSVLogger with the desired columns\n",
        "    logger = CSVLogger(log_csv, fieldnames=[\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"epoch_time_sec\"])\n",
        "    # track the best validation accuracy and the epoch when it occurred\n",
        "    best_val_acc, best_epoch = -1.0, -1\n",
        "    # compute total trainable parameters for reporting\n",
        "    param_count = count_parameters(model)\n",
        "    # iterate over the requested number of epochs\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        tr_loss, tr_acc, tr_time = train_one_epoch(model, train_loader, optimizer, device)\n",
        "        va_loss, va_acc = evaluate(model, val_loader, device)\n",
        "        # print a compact progress line for tracking\n",
        "        print(f\"[{arch_name} | val={val_fold}] epoch {epoch:03d} | \"\n",
        "              f\"train: loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "              f\"val: loss {va_loss:.4f} acc {va_acc:.4f} | \"\n",
        "              f\"time {tr_time:.1f}s\")\n",
        "        # log the epoch metrics to CSV\n",
        "        logger.log({\"epoch\": epoch, \"train_loss\": f\"{tr_loss:.6f}\", \"train_acc\": f\"{tr_acc:.6f}\",\n",
        "                    \"val_loss\": f\"{va_loss:.6f}\", \"val_acc\": f\"{va_acc:.6f}\", \"epoch_time_sec\": f\"{tr_time:.3f}\"})\n",
        "        # save the 'last' checkpoint snapshot for this epoch\n",
        "        save_checkpoint(last_ckpt, model, optimizer, epoch, va_acc, meta={\"arch\": arch_name, \"val_fold\": val_fold, \"run_id\": RUN_ID})\n",
        "        # if validation accuracy improved, update best and save the 'best-val' checkpoint\n",
        "        if va_acc > best_val_acc:\n",
        "            best_val_acc, best_epoch = va_acc, epoch\n",
        "            save_checkpoint(best_ckpt, model, optimizer, epoch, va_acc, meta={\"arch\": arch_name, \"val_fold\": val_fold, \"run_id\": RUN_ID})\n",
        "    # return a summary dict for this fold\n",
        "    return {\"arch\": arch_name, \"val_fold\": val_fold, \"best_val_acc\": best_val_acc, \"best_epoch\": best_epoch,\n",
        "            \"best_ckpt\": best_ckpt, \"last_ckpt\": last_ckpt, \"log_csv\": log_csv, \"params\": param_count}\n",
        "\n",
        "# create a global results dictionary to collect fold summaries per architecture\n",
        "RESULTS = {}\n",
        "\n",
        "# helper to record a fold result into the RESULTS dictionary\n",
        "def record_fold_result(summary: dict):\n",
        "    # extract architecture name and fold name from the summary\n",
        "    arch = summary[\"arch\"]\n",
        "    fold = summary[\"val_fold\"]\n",
        "    # create a nested dict for this architecture if not present\n",
        "    if arch not in RESULTS:\n",
        "        RESULTS[arch] = {}\n",
        "    RESULTS[arch][fold] = summary\n",
        "# helper to pick the best fold (highest val acc) for a given architecture\n",
        "def pick_arch_winner(arch_name: str):\n",
        "    # ensure we have results for this architecture\n",
        "    assert arch_name in RESULTS and len(RESULTS[arch_name]) > 0, f\"No results stored for architecture '{arch_name}'.\"\n",
        "    best_fold, best_acc, best_summary = None, -1.0, None\n",
        "    # iterate over folds and summaries for this architecture\n",
        "    for fold_name, summary in RESULTS[arch_name].items():\n",
        "        acc = summary[\"best_val_acc\"]\n",
        "        # if better than current best, update the trackers\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_fold = fold_name\n",
        "            best_summary = summary\n",
        "\n",
        "    print(f\"[WINNER | {arch_name}] fold={best_fold} | best_val_acc={best_acc:.4f} | ckpt={best_summary['best_ckpt']}\")\n",
        "    return best_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCJGnRhW78Py",
        "outputId": "68dbc6b6-4aa8-4316-b6c1-d847c81ca604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H1/Step-7 train transform: Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            ")\n",
            "H1/Step-7 test  transform: Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# ==== RESET FOR STEP-7 (plain, fair, reproducible) ====\n",
        "\n",
        "# 1) Hard reset determinism (same seed, deterministic kernels)\n",
        "SEED = 42\n",
        "import random, numpy as np, torch, torchvision, os\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True   # force deterministic kernels\n",
        "torch.backends.cudnn.benchmark = False      # DON'T autotune for Step-7\n",
        "\n",
        "# 2) Rebuild PLAIN transforms and datasets (NO augmentation for Step-7)\n",
        "_plain = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=DATA_DIR, train=True, download=False, transform=_plain\n",
        ")\n",
        "test_dataset  = torchvision.datasets.CIFAR10(\n",
        "    root=DATA_DIR, train=False, download=False, transform=_plain\n",
        ")\n",
        "\n",
        "# 3) Rebuild test_loader (plain)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
        ")\n",
        "\n",
        "# 4) Rebuild the 3 folds with the SAME seed\n",
        "n_total = len(train_dataset)\n",
        "rng = np.random.RandomState(SEED)\n",
        "all_indices = np.arange(n_total); rng.shuffle(all_indices)\n",
        "X_idx, Y_idx, Z_idx = np.array_split(all_indices, 3)\n",
        "FOLDS = {\"X\": X_idx.tolist(), \"Y\": Y_idx.tolist(), \"Z\": Z_idx.tolist()}\n",
        "\n",
        "# 5) Rebuild the fold loaders helper (PLAIN dataset; NO aug function)\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "loader_generator = torch.Generator(); loader_generator.manual_seed(SEED)\n",
        "\n",
        "def _make_loader(dataset, indices, batch_size, num_workers, pin_memory):\n",
        "    sampler = SubsetRandomSampler(indices, generator=loader_generator)\n",
        "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler,\n",
        "                      num_workers=num_workers, pin_memory=pin_memory, drop_last=False)\n",
        "\n",
        "def get_fold_loaders(val_fold: str, batch_size=BATCH_SIZE):\n",
        "    assert val_fold in FOLDS, f\"val_fold must be one of {list(FOLDS.keys())}\"\n",
        "    val_idx = FOLDS[val_fold]\n",
        "    train_idx = []\n",
        "    for name, idxs in FOLDS.items():\n",
        "        if name != val_fold:\n",
        "            train_idx.extend(idxs)\n",
        "    tr = _make_loader(train_dataset, train_idx, batch_size, NUM_WORKERS, PIN_MEMORY)\n",
        "    va = _make_loader(train_dataset, val_idx,   batch_size, NUM_WORKERS, PIN_MEMORY)\n",
        "    print(f\"[Fold with val={val_fold}] train samples: {len(train_idx)} | val samples: {len(val_idx)}\")\n",
        "    return tr, va\n",
        "\n",
        "# 6) Sanity print: make sure we are PLAIN\n",
        "print(\"H1/Step-7 train transform:\", train_dataset.transform)\n",
        "print(\"H1/Step-7 test  transform:\", test_dataset.transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQrQ4xE2Dk70",
        "outputId": "d1248877-ff80-4263-a059-eab49ca67155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arch-A (Fold-1) params: 1070986\n",
            "[Fold with val=X] train samples: 33333 | val samples: 16667\n",
            "[ArchA | val=X] epoch 001 | train: loss 1.4612 acc 0.4682 | val: loss 1.2190 acc 0.5630 | time 7.0s\n",
            "[ArchA | val=X] epoch 002 | train: loss 1.1404 acc 0.5895 | val: loss 1.0141 acc 0.6356 | time 7.0s\n",
            "[ArchA | val=X] epoch 003 | train: loss 0.9973 acc 0.6431 | val: loss 0.9426 acc 0.6673 | time 7.7s\n",
            "[ArchA | val=X] epoch 004 | train: loss 0.9084 acc 0.6762 | val: loss 0.8753 acc 0.6890 | time 8.0s\n",
            "[ArchA | val=X] epoch 005 | train: loss 0.8291 acc 0.7064 | val: loss 0.8748 acc 0.6900 | time 8.0s\n",
            "[ArchA | val=X] epoch 006 | train: loss 0.7781 acc 0.7229 | val: loss 0.7998 acc 0.7217 | time 7.8s\n",
            "[ArchA | val=X] epoch 007 | train: loss 0.7209 acc 0.7425 | val: loss 0.8247 acc 0.7110 | time 8.0s\n",
            "[ArchA | val=X] epoch 008 | train: loss 0.6694 acc 0.7633 | val: loss 0.8466 acc 0.7053 | time 8.0s\n",
            "[ArchA | val=X] epoch 009 | train: loss 0.6268 acc 0.7779 | val: loss 0.7666 acc 0.7371 | time 7.6s\n",
            "[ArchA | val=X] epoch 010 | train: loss 0.5819 acc 0.7957 | val: loss 0.7654 acc 0.7392 | time 7.1s\n",
            "Arch-B (Fold-1) params: 2777674\n",
            "[Fold with val=X] train samples: 33333 | val samples: 16667\n",
            "[ArchB | val=X] epoch 001 | train: loss 1.4102 acc 0.4814 | val: loss 1.6139 acc 0.4597 | time 22.4s\n",
            "[ArchB | val=X] epoch 002 | train: loss 0.9486 acc 0.6599 | val: loss 0.9863 acc 0.6545 | time 22.0s\n",
            "[ArchB | val=X] epoch 003 | train: loss 0.7223 acc 0.7445 | val: loss 1.0619 acc 0.6248 | time 21.9s\n",
            "[ArchB | val=X] epoch 004 | train: loss 0.5772 acc 0.7970 | val: loss 0.8193 acc 0.7173 | time 22.0s\n",
            "[ArchB | val=X] epoch 005 | train: loss 0.4751 acc 0.8335 | val: loss 1.1030 acc 0.6563 | time 22.0s\n",
            "[ArchB | val=X] epoch 006 | train: loss 0.3725 acc 0.8710 | val: loss 0.6836 acc 0.7757 | time 21.9s\n",
            "[ArchB | val=X] epoch 007 | train: loss 0.2944 acc 0.8974 | val: loss 1.2282 acc 0.6786 | time 21.9s\n",
            "[ArchB | val=X] epoch 008 | train: loss 0.2188 acc 0.9256 | val: loss 0.9803 acc 0.7086 | time 22.0s\n",
            "[ArchB | val=X] epoch 009 | train: loss 0.1500 acc 0.9515 | val: loss 0.9659 acc 0.7525 | time 22.1s\n",
            "[ArchB | val=X] epoch 010 | train: loss 0.1017 acc 0.9687 | val: loss 1.2274 acc 0.7094 | time 22.0s\n",
            "\n",
            "Fold-1 results:\n",
            "Arch-A: {'arch': 'ArchA', 'val_fold': 'X', 'best_val_acc': 0.7391852162956741, 'best_epoch': 10, 'best_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchA_valX_best-val.pth', 'last_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchA_valX_last.pth', 'log_csv': '/content/outputs/run_20251025-040551/logs/ArchA_valX_metrics.csv', 'params': 1070986}\n",
            "Arch-B: {'arch': 'ArchB', 'val_fold': 'X', 'best_val_acc': 0.7756644867102658, 'best_epoch': 6, 'best_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchB_valX_best-val.pth', 'last_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchB_valX_last.pth', 'log_csv': '/content/outputs/run_20251025-040551/logs/ArchB_valX_metrics.csv', 'params': 2777674}\n"
          ]
        }
      ],
      "source": [
        "# Fold-1 training (val = X; train = Y+Z) for both architectures\n",
        "\n",
        "EPOCHS_FOLD1 = 10\n",
        "LR_FOLD1 = 0.01\n",
        "\n",
        "# Arch-A on Fold-1 (val = X)\n",
        "\n",
        "# Arch-A model instance for this fold\n",
        "model_A_F1 = BasicCNN(num_classes=10).to(device)\n",
        "print(\"Arch-A (Fold-1) params:\", count_parameters(model_A_F1))\n",
        "# train Arch-A for fold-1 with CSV logging and checkpointing\n",
        "resA_X = train_for_fold_logged(model_A_F1, arch_name=\"ArchA\", val_fold=\"X\",\n",
        "                               num_epochs=EPOCHS_FOLD1, lr=LR_FOLD1)\n",
        "# store the fold-1 summary for Arch-A in the global RESULTS dict\n",
        "record_fold_result(resA_X)\n",
        "\n",
        "# Arch-B on Fold-1 (val = X)\n",
        "\n",
        "# Arch-B model instance for this fold\n",
        "model_B_F1 = ResNetLite(num_classes=10, base_width=64, layers=(2, 2, 2)).to(device)\n",
        "print(\"Arch-B (Fold-1) params:\", count_parameters(model_B_F1))\n",
        "# train Arch-B for fold-1 with CSV logging and checkpointing\n",
        "resB_X = train_for_fold_logged(model_B_F1, arch_name=\"ArchB\", val_fold=\"X\",\n",
        "                               num_epochs=EPOCHS_FOLD1, lr=LR_FOLD1)\n",
        "# store the fold-1 summary for Arch-B in the global RESULTS dict\n",
        "record_fold_result(resB_X)\n",
        "\n",
        "# print to confirm best validation results and checkpoint paths\n",
        "print(\"\\nFold-1 results:\")\n",
        "print(\"Arch-A:\", resA_X)\n",
        "print(\"Arch-B:\", resB_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWvxF3OaHNxU",
        "outputId": "71adb503-4c7a-4b4e-ea78-ebedd4840314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arch-A (Fold-2) params: 1070986\n",
            "[Fold with val=Y] train samples: 33333 | val samples: 16667\n",
            "[ArchA | val=Y] epoch 001 | train: loss 1.4605 acc 0.4697 | val: loss 1.2225 acc 0.5600 | time 8.0s\n",
            "[ArchA | val=Y] epoch 002 | train: loss 1.1555 acc 0.5856 | val: loss 1.1085 acc 0.5964 | time 8.1s\n",
            "[ArchA | val=Y] epoch 003 | train: loss 1.0170 acc 0.6393 | val: loss 0.9685 acc 0.6590 | time 7.8s\n",
            "[ArchA | val=Y] epoch 004 | train: loss 0.9162 acc 0.6751 | val: loss 0.8840 acc 0.6903 | time 7.1s\n",
            "[ArchA | val=Y] epoch 005 | train: loss 0.8401 acc 0.7031 | val: loss 0.8366 acc 0.7077 | time 7.2s\n",
            "[ArchA | val=Y] epoch 006 | train: loss 0.7760 acc 0.7249 | val: loss 0.8308 acc 0.7080 | time 7.2s\n",
            "[ArchA | val=Y] epoch 007 | train: loss 0.7203 acc 0.7429 | val: loss 0.8491 acc 0.7080 | time 7.4s\n",
            "[ArchA | val=Y] epoch 008 | train: loss 0.6799 acc 0.7597 | val: loss 0.8026 acc 0.7194 | time 8.4s\n",
            "[ArchA | val=Y] epoch 009 | train: loss 0.6311 acc 0.7783 | val: loss 0.7822 acc 0.7317 | time 8.1s\n",
            "[ArchA | val=Y] epoch 010 | train: loss 0.5949 acc 0.7906 | val: loss 0.7594 acc 0.7375 | time 8.0s\n",
            "Arch-B (Fold-2) params: 2777674\n",
            "[Fold with val=Y] train samples: 33333 | val samples: 16667\n",
            "[ArchB | val=Y] epoch 001 | train: loss 1.3941 acc 0.4829 | val: loss 1.1572 acc 0.5865 | time 22.4s\n",
            "[ArchB | val=Y] epoch 002 | train: loss 0.9242 acc 0.6699 | val: loss 1.5516 acc 0.5244 | time 22.0s\n",
            "[ArchB | val=Y] epoch 003 | train: loss 0.7160 acc 0.7468 | val: loss 0.8256 acc 0.7101 | time 21.7s\n",
            "[ArchB | val=Y] epoch 004 | train: loss 0.5680 acc 0.8006 | val: loss 0.8008 acc 0.7246 | time 22.0s\n",
            "[ArchB | val=Y] epoch 005 | train: loss 0.4703 acc 0.8341 | val: loss 0.8413 acc 0.7295 | time 22.1s\n",
            "[ArchB | val=Y] epoch 006 | train: loss 0.3892 acc 0.8634 | val: loss 0.9794 acc 0.6913 | time 21.9s\n",
            "[ArchB | val=Y] epoch 007 | train: loss 0.2981 acc 0.8951 | val: loss 1.3909 acc 0.6435 | time 21.9s\n",
            "[ArchB | val=Y] epoch 008 | train: loss 0.2199 acc 0.9236 | val: loss 0.9396 acc 0.7332 | time 22.0s\n",
            "[ArchB | val=Y] epoch 009 | train: loss 0.1644 acc 0.9456 | val: loss 1.2963 acc 0.6812 | time 22.0s\n",
            "[ArchB | val=Y] epoch 010 | train: loss 0.1194 acc 0.9606 | val: loss 0.8714 acc 0.7582 | time 22.0s\n",
            "\n",
            "Fold-2 results:\n",
            "Arch-A: {'arch': 'ArchA', 'val_fold': 'Y', 'best_val_acc': 0.7375052498950021, 'best_epoch': 10, 'best_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchA_valY_best-val.pth', 'last_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchA_valY_last.pth', 'log_csv': '/content/outputs/run_20251025-040551/logs/ArchA_valY_metrics.csv', 'params': 1070986}\n",
            "Arch-B: {'arch': 'ArchB', 'val_fold': 'Y', 'best_val_acc': 0.7582048359032819, 'best_epoch': 10, 'best_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchB_valY_best-val.pth', 'last_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchB_valY_last.pth', 'log_csv': '/content/outputs/run_20251025-040551/logs/ArchB_valY_metrics.csv', 'params': 2777674}\n"
          ]
        }
      ],
      "source": [
        "#  Fold-2 training (val = Y; train = X+Z) for both architectures\n",
        "\n",
        "EPOCHS_FOLD2 = 10\n",
        "LR_FOLD2 = 0.01\n",
        "\n",
        "# Arch-A on Fold-2 (val = Y)\n",
        "\n",
        "#Arch-A model instance for this fold\n",
        "model_A_F2 = BasicCNN(num_classes=10).to(device)\n",
        "print(\"Arch-A (Fold-2) params:\", count_parameters(model_A_F2))\n",
        "resA_Y = train_for_fold_logged(model_A_F2, arch_name=\"ArchA\", val_fold=\"Y\",\n",
        "                               num_epochs=EPOCHS_FOLD2, lr=LR_FOLD2)\n",
        "# store the fold-2 summary for Arch-A in the global RESULTS dict\n",
        "record_fold_result(resA_Y)\n",
        "\n",
        "#  Arch-B on Fold-2 (val = Y)\n",
        "\n",
        "# Arch-B model instance for this fold\n",
        "model_B_F2 = ResNetLite(num_classes=10, base_width=64, layers=(2, 2, 2)).to(device)\n",
        "print(\"Arch-B (Fold-2) params:\", count_parameters(model_B_F2))\n",
        "# train Arch-B for fold-2 with CSV logging and checkpointing\n",
        "resB_Y = train_for_fold_logged(model_B_F2, arch_name=\"ArchB\", val_fold=\"Y\",\n",
        "                               num_epochs=EPOCHS_FOLD2, lr=LR_FOLD2)\n",
        "# store the fold-2 summary for Arch-B in the global RESULTS dict\n",
        "record_fold_result(resB_Y)\n",
        "\n",
        "# print to confirm best validation results and checkpoint paths\n",
        "print(\"\\nFold-2 results:\")\n",
        "print(\"Arch-A:\", resA_Y)\n",
        "print(\"Arch-B:\", resB_Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV3jlakaI4AR",
        "outputId": "62d8b130-6f4f-46d5-be43-d85c792d3e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arch-A (Fold-3) params: 1070986\n",
            "[Fold with val=Z] train samples: 33334 | val samples: 16666\n",
            "[ArchA | val=Z] epoch 001 | train: loss 1.4822 acc 0.4613 | val: loss 1.1917 acc 0.5673 | time 8.0s\n",
            "[ArchA | val=Z] epoch 002 | train: loss 1.1653 acc 0.5857 | val: loss 1.0562 acc 0.6261 | time 7.9s\n",
            "[ArchA | val=Z] epoch 003 | train: loss 1.0222 acc 0.6366 | val: loss 1.0435 acc 0.6255 | time 8.1s\n",
            "[ArchA | val=Z] epoch 004 | train: loss 0.9298 acc 0.6701 | val: loss 0.8933 acc 0.6835 | time 7.8s\n",
            "[ArchA | val=Z] epoch 005 | train: loss 0.8500 acc 0.6995 | val: loss 0.8982 acc 0.6825 | time 7.0s\n",
            "[ArchA | val=Z] epoch 006 | train: loss 0.7833 acc 0.7218 | val: loss 0.8174 acc 0.7156 | time 6.8s\n",
            "[ArchA | val=Z] epoch 007 | train: loss 0.7388 acc 0.7371 | val: loss 0.7750 acc 0.7299 | time 6.9s\n",
            "[ArchA | val=Z] epoch 008 | train: loss 0.6850 acc 0.7585 | val: loss 0.7891 acc 0.7249 | time 7.5s\n",
            "[ArchA | val=Z] epoch 009 | train: loss 0.6304 acc 0.7780 | val: loss 0.7593 acc 0.7383 | time 8.0s\n",
            "[ArchA | val=Z] epoch 010 | train: loss 0.5911 acc 0.7870 | val: loss 0.7952 acc 0.7267 | time 8.0s\n",
            "Arch-B (Fold-3) params: 2777674\n",
            "[Fold with val=Z] train samples: 33334 | val samples: 16666\n",
            "[ArchB | val=Z] epoch 001 | train: loss 1.4088 acc 0.4829 | val: loss 1.2388 acc 0.5622 | time 22.4s\n",
            "[ArchB | val=Z] epoch 002 | train: loss 0.9529 acc 0.6594 | val: loss 1.0466 acc 0.6283 | time 22.0s\n",
            "[ArchB | val=Z] epoch 003 | train: loss 0.7393 acc 0.7403 | val: loss 0.9823 acc 0.6610 | time 21.8s\n",
            "[ArchB | val=Z] epoch 004 | train: loss 0.5906 acc 0.7949 | val: loss 1.0650 acc 0.6490 | time 21.9s\n",
            "[ArchB | val=Z] epoch 005 | train: loss 0.4809 acc 0.8324 | val: loss 0.8206 acc 0.7350 | time 22.0s\n",
            "[ArchB | val=Z] epoch 006 | train: loss 0.3798 acc 0.8658 | val: loss 1.1059 acc 0.6821 | time 21.9s\n",
            "[ArchB | val=Z] epoch 007 | train: loss 0.3062 acc 0.8932 | val: loss 0.7477 acc 0.7649 | time 22.0s\n",
            "[ArchB | val=Z] epoch 008 | train: loss 0.2244 acc 0.9237 | val: loss 0.8860 acc 0.7418 | time 22.0s\n",
            "[ArchB | val=Z] epoch 009 | train: loss 0.1610 acc 0.9455 | val: loss 0.8405 acc 0.7575 | time 22.0s\n",
            "[ArchB | val=Z] epoch 010 | train: loss 0.1024 acc 0.9679 | val: loss 1.2438 acc 0.7086 | time 21.9s\n",
            "\n",
            "Fold-3 results:\n",
            "Arch-A: {'arch': 'ArchA', 'val_fold': 'Z', 'best_val_acc': 0.7383295331813272, 'best_epoch': 9, 'best_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchA_valZ_best-val.pth', 'last_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchA_valZ_last.pth', 'log_csv': '/content/outputs/run_20251025-040551/logs/ArchA_valZ_metrics.csv', 'params': 1070986}\n",
            "Arch-B: {'arch': 'ArchB', 'val_fold': 'Z', 'best_val_acc': 0.764850594023761, 'best_epoch': 7, 'best_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchB_valZ_best-val.pth', 'last_ckpt': '/content/outputs/run_20251025-040551/checkpoints/ArchB_valZ_last.pth', 'log_csv': '/content/outputs/run_20251025-040551/logs/ArchB_valZ_metrics.csv', 'params': 2777674}\n",
            "[WINNER | ArchA] fold=X | best_val_acc=0.7392 | ckpt=/content/outputs/run_20251025-040551/checkpoints/ArchA_valX_best-val.pth\n",
            "[WINNER | ArchB] fold=X | best_val_acc=0.7757 | ckpt=/content/outputs/run_20251025-040551/checkpoints/ArchB_valX_best-val.pth\n"
          ]
        }
      ],
      "source": [
        "# Fold-3 (val = Z), pick winners per architecture, test both winners, pick final winner\n",
        "\n",
        "EPOCHS_FOLD3 = 10\n",
        "LR_FOLD3 = 0.01\n",
        "\n",
        "# Arch-A on Fold-3 (val = Z)\n",
        "\n",
        "# Arch-A model instance for this fold\n",
        "model_A_F3 = BasicCNN(num_classes=10).to(device)\n",
        "print(\"Arch-A (Fold-3) params:\", count_parameters(model_A_F3))\n",
        "# train Arch-A for fold-3 with CSV logging and checkpointing\n",
        "resA_Z = train_for_fold_logged(model_A_F3, arch_name=\"ArchA\", val_fold=\"Z\",\n",
        "                               num_epochs=EPOCHS_FOLD3, lr=LR_FOLD3)\n",
        "# store the fold-3 summary for Arch-A in the global RESULTS dict\n",
        "record_fold_result(resA_Z)\n",
        "\n",
        "#  Arch-B on Fold-3 (val = Z)\n",
        "\n",
        "# Arch-B model instance for this fold\n",
        "model_B_F3 = ResNetLite(num_classes=10, base_width=64, layers=(2, 2, 2)).to(device)\n",
        "print(\"Arch-B (Fold-3) params:\", count_parameters(model_B_F3))\n",
        "# train Arch-B for fold-3 with CSV logging and checkpointing\n",
        "resB_Z = train_for_fold_logged(model_B_F3, arch_name=\"ArchB\", val_fold=\"Z\",\n",
        "                               num_epochs=EPOCHS_FOLD3, lr=LR_FOLD3)\n",
        "# store the fold-3 summary for Arch-B in the global RESULTS dict\n",
        "record_fold_result(resB_Z)\n",
        "\n",
        "# print to confirm best validation results and checkpoint paths for Fold-3\n",
        "print(\"\\nFold-3 results:\")\n",
        "print(\"Arch-A:\", resA_Z)\n",
        "print(\"Arch-B:\", resB_Z)\n",
        "\n",
        "# Pick winners per architecture across all three folds\n",
        "\n",
        "# choose the best fold for Arch-A based on highest validation accuracy\n",
        "winA = pick_arch_winner(\"ArchA\")\n",
        "# choose the best fold for Arch-B based on highest validation accuracy\n",
        "winB = pick_arch_winner(\"ArchB\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8BIpSOrLVh1",
        "outputId": "77e41da3-973b-4c0e-ec14-91b148613625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Arch-A winner (fold=X) | loss 0.7800 | acc 0.7357\n",
            "[TEST] Arch-B winner (fold=X) | loss 0.6813 | acc 0.7705\n",
            "[FINAL WINNER] ArchB | fold=X | test_acc=0.7705 | ckpt=/content/outputs/run_20251025-040551/checkpoints/ArchB_valX_best-val.pth\n"
          ]
        }
      ],
      "source": [
        "# Test both architecture winners and choose overall winner\n",
        "\n",
        "# helper that builds a fresh model instance by architecture name\n",
        "def build_model_for_arch(arch_name: str):\n",
        "    if arch_name == \"ArchA\":\n",
        "        return BasicCNN(num_classes=10).to(device)\n",
        "    elif arch_name == \"ArchB\":\n",
        "        return ResNetLite(num_classes=10, base_width=64, layers=(2, 2, 2)).to(device)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown architecture name: {arch_name}\")\n",
        "\n",
        "# helper that loads 'best-val' weights into a fresh model using a winner summary dict\n",
        "def load_best_model(winner_summary: dict):\n",
        "    model = build_model_for_arch(winner_summary[\"arch\"])\n",
        "    state = torch.load(winner_summary[\"best_ckpt\"], map_location=device)\n",
        "    model.load_state_dict(state[\"model_state\"])\n",
        "    model.eval()\n",
        "    # return the ready-to-evaluate model\n",
        "    return model\n",
        "\n",
        "# build and load the Arch-A winner model\n",
        "model_A_win = load_best_model(winA)\n",
        "# evaluate the Arch-A winner on the 10k CIFAR-10 test set\n",
        "test_loss_A, test_acc_A = evaluate(model_A_win, test_loader, device)\n",
        "print(f\"[TEST] Arch-A winner (fold={winA['val_fold']}) | loss {test_loss_A:.4f} | acc {test_acc_A:.4f}\")\n",
        "\n",
        "# build and load the Arch-B winner model\n",
        "model_B_win = load_best_model(winB)\n",
        "# evaluate the Arch-B winner on the 10k CIFAR-10 test set\n",
        "test_loss_B, test_acc_B = evaluate(model_B_win, test_loader, device)\n",
        "print(f\"[TEST] Arch-B winner (fold={winB['val_fold']}) | loss {test_loss_B:.4f} | acc {test_acc_B:.4f}\")\n",
        "\n",
        "# select the final overall winner by higher test accuracy\n",
        "if test_acc_A >= test_acc_B:\n",
        "    final_winner = {\"arch\": \"ArchA\", \"fold\": winA[\"val_fold\"], \"test_acc\": float(test_acc_A), \"ckpt\": winA[\"best_ckpt\"]}\n",
        "# otherwise Arch-B has strictly higher test accuracy\n",
        "else:\n",
        "    final_winner = {\"arch\": \"ArchB\", \"fold\": winB[\"val_fold\"], \"test_acc\": float(test_acc_B), \"ckpt\": winB[\"best_ckpt\"]}\n",
        "\n",
        "print(f\"[FINAL WINNER] {final_winner['arch']} | fold={final_winner['fold']} | test_acc={final_winner['test_acc']:.4f} | ckpt={final_winner['ckpt']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "57E2x_5yxKvz",
        "outputId": "f36c6d5c-351a-4f19-ab9c-f789c823fbe9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def plot_clean_confusion_matrix(model, test_loader, class_names, title):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Confusion Matrix - {title}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Verify row sums\n",
        "    row_sums = cm.sum(axis=1)\n",
        "    print(\"Row sums (should all be 1000):\", row_sums)\n",
        "    \n",
        "    return cm\n",
        "\n",
        "# Regenerate for your models\n",
        "cm_archB = plot_clean_confusion_matrix(model_B_win, test_loader, class_names, \"Arch-B Winner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21LTNjENXgIO",
        "outputId": "8d9f8578-1159-431b-cc90-b7d624ca0065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold sizes: {'X': 16667, 'Y': 16667, 'Z': 16666}\n",
            "H1 train transform: Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            ")\n",
            "H1 test  transform: Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# --- Quick sanity reset before H1: plain datasets + loaders for a clean H1 run ---\n",
        "\n",
        "import torchvision, torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# 1) Plain (no augmentation) transforms for H1\n",
        "_plain = T.Compose([T.ToTensor(), T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "# 2) Recreate datasets (do NOT use the H2 augmented ones)\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,  download=False, transform=_plain)\n",
        "test_dataset  = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=False, transform=_plain)\n",
        "\n",
        "# 3) Rebuild test loader (plain)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "# 4) Rebuild the 3-fold split deterministically\n",
        "rng = np.random.RandomState(SEED)\n",
        "idx = np.arange(len(train_dataset))\n",
        "rng.shuffle(idx)\n",
        "X_idx, Y_idx, Z_idx = np.array_split(idx, 3)\n",
        "FOLDS = {\"X\": X_idx.tolist(), \"Y\": Y_idx.tolist(), \"Z\": Z_idx.tolist()}\n",
        "print(\"Fold sizes:\", {k: len(v) for k,v in FOLDS.items()})\n",
        "\n",
        "# 5) Quick check of transforms being used\n",
        "print(\"H1 train transform:\", train_dataset.transform)\n",
        "print(\"H1 test  transform:\", test_dataset.transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IOSKI0pSbuTo"
      },
      "outputs": [],
      "source": [
        "del final_winner_model, model_A_win, model_B_win\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6ltBhxjMhvC",
        "outputId": "3f63b247-0e11-4d5c-84a4-219c35bd2936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Fold with val=X] train samples: 33333 | val samples: 16667\n",
            "[H1_bw32 | val=X] epoch 001 | train: loss 1.4789 acc 0.4556 | val: loss 1.4024 acc 0.4928 | time 13.4s\n",
            "[H1_bw32 | val=X] epoch 002 | train: loss 1.0204 acc 0.6353 | val: loss 0.9770 acc 0.6506 | time 13.5s\n",
            "[H1_bw32 | val=X] epoch 003 | train: loss 0.8455 acc 0.6996 | val: loss 1.0686 acc 0.6207 | time 13.4s\n",
            "[H1_bw32 | val=X] epoch 004 | train: loss 0.7071 acc 0.7495 | val: loss 1.0007 acc 0.6678 | time 13.3s\n",
            "[H1_bw32 | val=X] epoch 005 | train: loss 0.6045 acc 0.7865 | val: loss 0.9236 acc 0.7031 | time 13.4s\n",
            "[H1_bw32 | val=X] epoch 006 | train: loss 0.5202 acc 0.8183 | val: loss 1.2134 acc 0.6461 | time 13.3s\n",
            "[H1_bw32 | val=X] epoch 007 | train: loss 0.4514 acc 0.8451 | val: loss 0.8808 acc 0.7059 | time 13.8s\n",
            "[H1_bw32 | val=X] epoch 008 | train: loss 0.3765 acc 0.8704 | val: loss 0.8872 acc 0.7332 | time 13.4s\n",
            "[H1_bw32 | val=X] epoch 009 | train: loss 0.3142 acc 0.8927 | val: loss 0.7771 acc 0.7557 | time 13.4s\n",
            "[H1_bw32 | val=X] epoch 010 | train: loss 0.2611 acc 0.9100 | val: loss 0.7897 acc 0.7538 | time 13.6s\n",
            "[Fold with val=X] train samples: 33333 | val samples: 16667\n",
            "[H1_bw96 | val=X] epoch 001 | train: loss 1.3945 acc 0.4878 | val: loss 1.2272 acc 0.5546 | time 41.7s\n",
            "[H1_bw96 | val=X] epoch 002 | train: loss 0.9293 acc 0.6694 | val: loss 0.9499 acc 0.6765 | time 41.3s\n",
            "[H1_bw96 | val=X] epoch 003 | train: loss 0.7069 acc 0.7538 | val: loss 1.0082 acc 0.6581 | time 41.6s\n",
            "[H1_bw96 | val=X] epoch 004 | train: loss 0.5537 acc 0.8081 | val: loss 0.8463 acc 0.7281 | time 41.5s\n",
            "[H1_bw96 | val=X] epoch 005 | train: loss 0.4235 acc 0.8511 | val: loss 0.9355 acc 0.7124 | time 41.5s\n",
            "[H1_bw96 | val=X] epoch 006 | train: loss 0.3250 acc 0.8867 | val: loss 1.1733 acc 0.6875 | time 41.7s\n",
            "[H1_bw96 | val=X] epoch 007 | train: loss 0.2365 acc 0.9173 | val: loss 0.9981 acc 0.7309 | time 41.7s\n",
            "[H1_bw96 | val=X] epoch 008 | train: loss 0.1670 acc 0.9437 | val: loss 0.9400 acc 0.7493 | time 41.6s\n",
            "[H1_bw96 | val=X] epoch 009 | train: loss 0.1197 acc 0.9605 | val: loss 0.9837 acc 0.7611 | time 41.6s\n",
            "[H1_bw96 | val=X] epoch 010 | train: loss 0.0708 acc 0.9785 | val: loss 0.8320 acc 0.7863 | time 41.6s\n",
            "\n",
            "[H1 COMPARISON]\n",
            "SMALL (bw=32) | val_best=0.7557 (ep9) | test_acc=0.7550\n",
            "BASE  (bw=64) | val_best=0.7757 (ep6) | test_acc=0.7705\n",
            "LARGE (bw=96) | val_best=0.7863 (ep10) | test_acc=0.7786\n",
            "H1 complete.\n"
          ]
        }
      ],
      "source": [
        "# Does changing model size (base_width) change performance? Fold = X\n",
        "\n",
        "# build→train→load_best→test for a given base_width using your Part-1 recipe\n",
        "def _run_bw_X(bw: int, tag: str):\n",
        "    # make model with requested width\n",
        "    model = ResNetLite(num_classes=10, base_width=bw, layers=(2,2,2)).to(device)\n",
        "    # train on Fold-X with the same Part-1 trainer (SGD, CE, 10 epochs)\n",
        "    summary = train_for_fold_logged(model, arch_name=tag, val_fold=\"X\", num_epochs=10, lr=0.01)\n",
        "    # keep result for bookkeeping\n",
        "    record_fold_result(summary)\n",
        "    # reload best weights into a fresh model and eval on test set\n",
        "    m = ResNetLite(num_classes=10, base_width=bw, layers=(2,2,2)).to(device)\n",
        "    state = torch.load(summary[\"best_ckpt\"], map_location=device); m.load_state_dict(state[\"model_state\"]); m.eval()\n",
        "    # compute test metrics on your existing test_loader\n",
        "    tl, ta = evaluate(m, test_loader, device)\n",
        "    # return summary + test numbers\n",
        "    return summary, float(tl), float(ta)\n",
        "\n",
        "# get baseline (bw=64) from Part-1 RESULTS; if missing, train it\n",
        "base = RESULTS.get(\"ArchB\", {}).get(\"X\")\n",
        "if base is None:\n",
        "    base, _, _ = _run_bw_X(64, \"H1_bw64\")\n",
        "\n",
        "# run SMALL (bw=32) and LARGE (bw=96)\n",
        "small, tl_s, ta_s = _run_bw_X(32, \"H1_bw32\")\n",
        "large, tl_l, ta_l = _run_bw_X(96, \"H1_bw96\")\n",
        "\n",
        "# evaluate baseline on test \n",
        "m64 = ResNetLite(num_classes=10, base_width=64, layers=(2,2,2)).to(device)\n",
        "st64 = torch.load(base[\"best_ckpt\"], map_location=device); m64.load_state_dict(st64[\"model_state\"]); m64.eval()\n",
        "tl_b, ta_b = evaluate(m64, test_loader, device)\n",
        "\n",
        "# print compact comparison\n",
        "print(\"\\n[H1 COMPARISON]\")\n",
        "print(f\"SMALL (bw=32) | val_best={small['best_val_acc']:.4f} (ep{small['best_epoch']}) | test_acc={ta_s:.4f}\")\n",
        "print(f\"BASE  (bw=64) | val_best={base['best_val_acc']:.4f} (ep{base['best_epoch']}) | test_acc={ta_b:.4f}\")\n",
        "print(f\"LARGE (bw=96) | val_best={large['best_val_acc']:.4f} (ep{large['best_epoch']}) | test_acc={ta_l:.4f}\")\n",
        "print(\"H1 complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3J1XsmvXedh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IktPTxL-T73u",
        "outputId": "41bd37f4-4678-4ec1-9207-88e1c91bfefa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "[H2|val=X] epoch 01 | train 1.7051/0.4332 | val 1.7746/0.4667 | time 26.0s\n",
            "[H2|val=X] epoch 02 | train 1.3617/0.6182 | val 1.5659/0.5597 | time 26.3s\n",
            "[H2|val=X] epoch 03 | train 1.2122/0.6906 | val 1.3405/0.6810 | time 25.9s\n",
            "[H2|val=X] epoch 04 | train 1.1031/0.7427 | val 1.1411/0.7511 | time 25.9s\n",
            "[H2|val=X] epoch 05 | train 1.0306/0.7817 | val 1.1129/0.7497 | time 26.1s\n",
            "[H2|val=X] epoch 06 | train 0.9826/0.8032 | val 1.0903/0.7632 | time 26.8s\n",
            "[H2|val=X] epoch 07 | train 0.9363/0.8229 | val 1.0297/0.7921 | time 26.1s\n",
            "[H2|val=X] epoch 08 | train 0.9096/0.8374 | val 0.9823/0.8128 | time 27.0s\n",
            "[H2|val=X] epoch 09 | train 0.8819/0.8496 | val 1.0168/0.8001 | time 27.0s\n",
            "[H2|val=X] epoch 10 | train 0.8514/0.8641 | val 0.9792/0.8134 | time 26.6s\n",
            "[TEST|H2] REG (aug+LS) | loss 0.9922 | acc 0.8114 | best_val=0.8134 (ep10)\n",
            "[TEST|H2] BASE (no-aug) | loss 1.4144 | acc 0.7705\n",
            "\n",
            "[H2 RESULT] REG acc=0.8114  vs  BASE acc=0.7705\n"
          ]
        }
      ],
      "source": [
        "#Needs more regularization for better training. (justify) (test) (yes/no) (explain)\n",
        "#regularization via Crop+Flip + Label Smoothing on Fold-X, with robust fallbacks\n",
        "\n",
        "import os, glob, time\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import torchvision, torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "try:\n",
        "    NUM_WORKERS\n",
        "except NameError:\n",
        "    NUM_WORKERS = 0\n",
        "PIN_MEMORY = bool(torch.cuda.is_available())\n",
        "\n",
        "# ensure a deterministic generator exists for samplers\n",
        "if \"loader_generator\" not in globals():\n",
        "    loader_generator = torch.Generator()\n",
        "    loader_generator.manual_seed(42)\n",
        "\n",
        "# ensure DATA_DIR exists (fallback to ./data if not set)\n",
        "try:\n",
        "    DATA_DIR\n",
        "except NameError:\n",
        "    DATA_DIR = \"./data\"\n",
        "\n",
        "# ensure BATCH_SIZE exists (fallback to 128)\n",
        "try:\n",
        "    BATCH_SIZE\n",
        "except NameError:\n",
        "    BATCH_SIZE = 128\n",
        "\n",
        "# ensure the ResNetLite class exists in scope; if not, raise a helpful error\n",
        "assert \"ResNetLite\" in globals(), \"ResNetLite class is not defined in this session. Re-run the cell where you defined it.\"\n",
        "\n",
        "# rebuild FOLDS if missing (same 3-way split as Part-1, deterministic)\n",
        "if \"FOLDS\" not in globals():\n",
        "    all_idx = list(range(50000))\n",
        "    g = torch.Generator(); g.manual_seed(42); perm = torch.randperm(50000, generator=g).tolist()\n",
        "    all_idx = [all_idx[i] for i in perm]\n",
        "    X = all_idx[:16667]; Y = all_idx[16667:33334]; Z = all_idx[33334:]\n",
        "    FOLDS = {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
        "    print(\"FOLDS was missing — rebuilt deterministically.\")\n",
        "\n",
        "# build train-time augmentation and plain eval transforms\n",
        "train_aug = T.Compose([T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])\n",
        "eval_plain = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])\n",
        "\n",
        "# instantiate CIFAR-10 datasets with the chosen transforms\n",
        "ds_train_aug   = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,  download=True, transform=train_aug)\n",
        "ds_train_plain = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,  download=False, transform=eval_plain)\n",
        "ds_test_plain  = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=False, transform=eval_plain)\n",
        "\n",
        "# pick Fold-X indices and build the complementary training indices\n",
        "val_idx   = FOLDS[\"X\"]\n",
        "train_idx = [i for k, idxs in FOLDS.items() if k != \"X\" for i in idxs]\n",
        "\n",
        "# create DataLoaders (aug for train, plain for val/test)\n",
        "train_loader = DataLoader(ds_train_aug, batch_size=BATCH_SIZE,\n",
        "                          sampler=SubsetRandomSampler(train_idx, generator=loader_generator),\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n",
        "val_loader   = DataLoader(ds_train_plain, batch_size=BATCH_SIZE,\n",
        "                          sampler=SubsetRandomSampler(val_idx, generator=loader_generator),\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n",
        "test_loader_ = DataLoader(ds_test_plain, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "# build the winner architecture fresh (ResNetLite, bw=64)\n",
        "model = ResNetLite(num_classes=10, base_width=64, layers=(2,2,2)).to(device)\n",
        "\n",
        "# define CrossEntropy with label smoothing (regularization)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "# use SGD+momentum as in Part-1\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# train for 10 epochs using your Part-1-style loop (simple + robust)\n",
        "best_val, best_ep = -1.0, -1\n",
        "for ep in range(1, 11):\n",
        "    # put model in train mode and init counters\n",
        "    model.train(); start = time.time(); tot=0; correct=0; loss_sum=0.0\n",
        "    # iterate over training batches\n",
        "    for x,y in train_loader:\n",
        "        # move to device\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        # zero grads\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # forward\n",
        "        logits = model(x)\n",
        "        # loss\n",
        "        loss = criterion(logits, y)\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        # step\n",
        "        optimizer.step()\n",
        "        # accumulate stats\n",
        "        loss_sum += loss.item() * y.size(0); tot += y.size(0); correct += (logits.argmax(1) == y).sum().item()\n",
        "    # compute training metrics\n",
        "    tr_loss = loss_sum / max(1, tot); tr_acc = correct / max(1, tot)\n",
        "    # evaluate on validation loader\n",
        "    with torch.no_grad():\n",
        "        model.eval(); v_tot=0; v_cor=0; v_loss=0.0\n",
        "        for xv, yv in val_loader:\n",
        "            xv, yv = xv.to(device), yv.to(device)\n",
        "            out = model(xv)\n",
        "            loss_v = criterion(out, yv)\n",
        "            v_loss += loss_v.item() * yv.size(0); v_tot += yv.size(0); v_cor += (out.argmax(1) == yv).sum().item()\n",
        "        va_loss = v_loss / max(1, v_tot); va_acc = v_cor / max(1, v_tot)\n",
        "    # print epoch progress\n",
        "    print(f\"[H2|val=X] epoch {ep:02d} | train {tr_loss:.4f}/{tr_acc:.4f} | val {va_loss:.4f}/{va_acc:.4f} | time {time.time()-start:.1f}s\")\n",
        "    # track best validation\n",
        "    if va_acc > best_val: best_val, best_ep = va_acc, ep\n",
        "\n",
        "# evaluate the regularized model on the 10k test set\n",
        "with torch.no_grad():\n",
        "    model.eval(); t_tot=0; t_cor=0; t_loss=0.0\n",
        "    for xt, yt in test_loader_:\n",
        "        xt, yt = xt.to(device), yt.to(device)\n",
        "        out = model(xt)\n",
        "        loss_t = criterion(out, yt)\n",
        "        t_loss += loss_t.item() * yt.size(0); t_tot += yt.size(0); t_cor += (out.argmax(1) == yt).sum().item()\n",
        "    test_loss_reg = t_loss / max(1, t_tot); test_acc_reg = t_cor / max(1, t_tot)\n",
        "\n",
        "# print the regularized model test metrics\n",
        "print(f\"[TEST|H2] REG (aug+LS) | loss {test_loss_reg:.4f} | acc {test_acc_reg:.4f} | best_val={best_val:.4f} (ep{best_ep})\")\n",
        "\n",
        "# try to locate a Part-1 baseline checkpoint for Arch-B Fold-X even if RESULTS is missing\n",
        "ckpt_guess = None\n",
        "if \"RESULTS\" in globals() and \"ArchB\" in RESULTS and \"X\" in RESULTS[\"ArchB\"]:\n",
        "    ckpt_guess = RESULTS[\"ArchB\"][\"X\"][\"best_ckpt\"]\n",
        "else:\n",
        "    # search common filename under your checkpoints directory\n",
        "    try:\n",
        "        CKPT_DIR\n",
        "    except NameError:\n",
        "        CKPT_DIR = \"./outputs/checkpoints\"\n",
        "    # look for ArchB Fold-X best checkpoint\n",
        "    matches = glob.glob(os.path.join(CKPT_DIR, \"*ArchB*valX*best-val.pth\"))\n",
        "    ckpt_guess = matches[0] if matches else None\n",
        "\n",
        "# if we found a baseline checkpoint, load and compare; otherwise warn and skip comparison\n",
        "if ckpt_guess is not None:\n",
        "    # build a fresh baseline model and load weights\n",
        "    base_model = ResNetLite(num_classes=10, base_width=64, layers=(2,2,2)).to(device)\n",
        "    state = torch.load(ckpt_guess, map_location=device)\n",
        "    base_model.load_state_dict(state[\"model_state\"])\n",
        "    base_model.eval()\n",
        "    # evaluate baseline on the same test loader\n",
        "    with torch.no_grad():\n",
        "        bt, bc, bl = 0, 0, 0.0\n",
        "        for xt, yt in test_loader_:\n",
        "            xt, yt = xt.to(device), yt.to(device)\n",
        "            out = base_model(xt)\n",
        "            l = criterion(out, yt)\n",
        "            bl += l.item() * yt.size(0); bt += yt.size(0); bc += (out.argmax(1) == yt).sum().item()\n",
        "        test_loss_base = bl / max(1, bt); test_acc_base = bc / max(1, bt)\n",
        "    # print side-by-side comparison\n",
        "    print(f\"[TEST|H2] BASE (no-aug) | loss {test_loss_base:.4f} | acc {test_acc_base:.4f}\")\n",
        "    print(f\"\\n[H2 RESULT] REG acc={test_acc_reg:.4f}  vs  BASE acc={test_acc_base:.4f}\")\n",
        "else:\n",
        "    # notify that we could not find a baseline checkpoint\n",
        "    print(\"\\n[H2 NOTICE] Could not find Part-1 baseline checkpoint (ArchB Fold-X). Report REG numbers above, or re-run Part-1 Step-7 to regenerate.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P83LCsRJSiD5",
        "outputId": "802726db-ec87-41b9-92f2-b56c62ee4a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[H3-best|sgd] ep01 | train 1.5393/0.4276 | val 1.4600/0.4817\n",
            "[H3-best|sgd] ep02 | train 1.0874/0.6109 | val 1.5242/0.5322\n",
            "[H3-best|sgd] ep03 | train 0.8876/0.6883 | val 1.1908/0.6080\n",
            "[H3-best|sgd] ep04 | train 0.7462/0.7355 | val 0.9324/0.7033\n",
            "[H3-best|sgd] ep05 | train 0.6520/0.7702 | val 0.8995/0.7017\n",
            "[H3-best|sgd] ep06 | train 0.5813/0.7991 | val 1.1136/0.6635\n",
            "[H3-best|sgd] ep07 | train 0.5296/0.8151 | val 0.6797/0.7808\n",
            "[H3-best|sgd] ep08 | train 0.4865/0.8301 | val 0.6735/0.7781\n",
            "[H3-best|sgd] ep09 | train 0.4554/0.8400 | val 0.7568/0.7457\n",
            "[H3-best|sgd] ep10 | train 0.4138/0.8548 | val 0.6927/0.7777\n",
            "[H3-best|adamw] ep01 | train 1.4340/0.4742 | val 1.2242/0.5648\n",
            "[H3-best|adamw] ep02 | train 1.0281/0.6335 | val 1.1431/0.6146\n",
            "[H3-best|adamw] ep03 | train 0.8508/0.7001 | val 0.9486/0.6723\n",
            "[H3-best|adamw] ep04 | train 0.7184/0.7487 | val 0.9780/0.6817\n",
            "[H3-best|adamw] ep05 | train 0.6339/0.7804 | val 0.6397/0.7805\n",
            "[H3-best|adamw] ep06 | train 0.5611/0.8056 | val 0.7824/0.7455\n",
            "[H3-best|adamw] ep07 | train 0.5148/0.8226 | val 0.6279/0.7852\n",
            "[H3-best|adamw] ep08 | train 0.4686/0.8390 | val 0.5414/0.8161\n",
            "[H3-best|adamw] ep09 | train 0.4309/0.8511 | val 0.5584/0.8132\n",
            "[H3-best|adamw] ep10 | train 0.4046/0.8592 | val 0.5743/0.8103\n",
            "\n",
            "[H3 COMPARISON — best epoch tested]\n",
            "SGD   | val_best=0.7808 (ep7) | test_acc=0.7834\n",
            "AdamW | val_best=0.8161 (ep8) | test_acc=0.8096\n"
          ]
        }
      ],
      "source": [
        "#Changing the optimizer (e.g: from SGD to Adam) improves performance (justify) (test) (yes/no) (explain)\n",
        "import copy, torch.nn as nn, torch.optim as optim\n",
        "\n",
        "# use plain CE to isolate optimizer effect (set to 0.1 if you want LS)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
        "\n",
        "def run_opt_best(opt_name, lr, wd):\n",
        "    # fresh model\n",
        "    model = ResNetLite(num_classes=10, base_width=64, layers=(2,2,2)).to(device)\n",
        "    # optimizer\n",
        "    optimizer = (optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "                 if opt_name==\"adamw\" else\n",
        "                 optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd))\n",
        "    # track best\n",
        "    best_val, best_ep, best_state = -1.0, -1, None\n",
        "    # train 10 epochs, keep best weights in memory\n",
        "    for ep in range(1, 11):\n",
        "        tr_loss, tr_acc = _train_epoch_adapt(model, train_loader, criterion, optimizer, device)\n",
        "        va_loss, va_acc = _eval_adapt(model, val_loader, device)\n",
        "        print(f\"[H3-best|{opt_name}] ep{ep:02d} | train {tr_loss:.4f}/{tr_acc:.4f} | val {va_loss:.4f}/{va_acc:.4f}\")\n",
        "        if va_acc > best_val:\n",
        "            best_val, best_ep, best_state = va_acc, ep, copy.deepcopy(model.state_dict())\n",
        "    # restore best weights and test\n",
        "    model.load_state_dict(best_state); model.eval()\n",
        "    tl, ta = _eval_adapt(model, TEST_LOADER, device)\n",
        "    return {\"opt\": opt_name, \"val_best\": best_val, \"best_ep\": best_ep, \"test_acc\": float(ta), \"test_loss\": float(tl)}\n",
        "\n",
        "# run both with reasonable defaults\n",
        "res_sgd_best   = run_opt_best(\"sgd\",   lr=0.01,  wd=5e-4)\n",
        "res_adamw_best = run_opt_best(\"adamw\", lr=3e-4,  wd=1e-4)\n",
        "\n",
        "# summary\n",
        "print(\"\\n[H3 COMPARISON — best epoch tested]\")\n",
        "print(f\"SGD   | val_best={res_sgd_best['val_best']:.4f} (ep{res_sgd_best['best_ep']}) | test_acc={res_sgd_best['test_acc']:.4f}\")\n",
        "print(f\"AdamW | val_best={res_adamw_best['val_best']:.4f} (ep{res_adamw_best['best_ep']}) | test_acc={res_adamw_best['test_acc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tiJSnrjpji-"
      },
      "source": [
        "Does changing to Adam/AdamW improve performance?\n",
        "\n",
        "Yes\n",
        "SGD → best val 0.7808 (ep7) → test 0.7834\n",
        "AdamW → best val 0.8161 (ep8) → test 0.8096\n",
        "\n",
        "Justification\n",
        "Adaptive steps: Adam/AdamW scales updates per-parameter using first/second moments → faster, more stable progress early, especially with short training (10 epochs).\n",
        "\n",
        "Decoupled weight decay (AdamW): cleaner L2 regularization than Adam’s original L2-as-grad, often better generalization.\n",
        "\n",
        "Short budget effect: With only 10 epochs, AdamW often reaches a better solution sooner. With more epochs + tuned schedules, SGD can catch up or tie (so the conclusion is contingent on this training budget).\n",
        "\n",
        "Changing from SGD to AdamW improved performance under the same 10-epoch setup (SGD 78.34% → AdamW 80.96% test). Reason: AdamW’s adaptive updates and decoupled weight decay converge faster and generalize better in short training; with longer training and tuned schedules, SGD may close the gap."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
